import logging
from collections import defaultdict
from typing import Tuple, Dict, List, DefaultDict, Callable, Any
import networkx as nx

from npuperf.classes.depthfirst.data_copy_layer import DataCopyAction, DataCopyLayer
from npuperf.classes.hardware.architecture.memory_hierarchy import MemoryHierarchy
from npuperf.classes.hardware.architecture.memory_level import MemoryLevel
from npuperf.classes.opt.temporal.loma.memory_allocator import MemHierarchyTooSmallException
from npuperf.classes.stages.Stage import Stage
from npuperf.classes.workload.dnn_workload import DNNWorkload
from npuperf.classes.workload.layer_node import LayerNode, InputLayerNode
from npuperf.classes.workload.mem_node import MemNode
from npuperf.utils import pickle_deepcopy
from math import prod

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)


# TODO: Feature: multicore
# TODO: bias
# bias buffer 是独立的，而且没有 O = A * B + C 的解析逻辑，要么加解析逻辑
# 要么就不建模bias buffer，我可以在conv 的latency加上一个额外的系数？



# To avoid unpickable lambda's
def return_0():
    return 0
def return_empty_list():
    return []
def return_0_0_list():
    return [0,0]
def return_emtpystr_0_list():
    return ['', 0]
def return_emtpystr_0_tuple():
    return ('', 0)
def return_empty_dict():
    return {}


def get_largest_alive_size(corrected_workload: DNNWorkload, permanent_data: Dict[LayerNode, int] = {}):
    """
    计算最大的同时存在片上的feature大小
    :param permanet_data: 是cache的数据量
    :return:
    """

    # 相比原来的函数，需要识别出residual层，然后residual层的较远的那个input node存在residual buffer
    # Q: 是往output buffer 和residual buffer都存吗
    # A：都存的话，这个函数应该不用改。不是的话需要改这个函数，同时后续获取residual这片输入要想办法定位到residual buffer(run for tile size)

    # Q: 识别出residual中需要存储在residual buffer的node
    # A: 自顶向下推理的话，对出度为2 的node，其输出往output buffer和residual buffer写，这里的size 就不统计往residual buffer写的size了
    # ? 这个想法不太好，后续concat、两个分支都做卷积的结构就没法做区分了，识别一下equation？ 但不知道咋弄，有待思考，初版先这样，后续再说
    # todo：不仅识别 out_degree == 2, 还要识别 operand_type == Add

    # Q：要新增支持其他算子，硬件方面还要添加其他的buffer，workload 的描述里应该更详细吗？
    # A: 是的。同时对于上面那个问题，就只能在workload里添加新的结电标识了。
    #    原本的网络描述只从equation 解析，现在因为新加了算子，还有其他的buffer，那workload 的信息应该给的更多才是.
    #    首先应该添加 operand_type, 给出算子类型，注意首字母大写。目前考虑的应该有以下几个: Conv, Pool, Add, Transpose, Concat, ConvTranspose

    # Q: 如果residual 被stack cut了(residual 是stack的第一个node)，加载数据的时候，一个往I1加载，一个往residual buffer里加载，这个咋做？？
    # A：识别入度为2 的节点，然后一个在I1，一个在R，问题同上，没法区分两个分支的卷积
    # todo：不仅识别 in_degree == 2, 还要识别 operand_type == Add

    # find maximum size of feature map stuff in memory at same time,
    # to then reserve this space before figuring out where cache should go

    current_size = [0]
    largest_input_plus_output_size = [0]
    def add_to_size(s):
        current_size[0] += s
        largest_input_plus_output_size[0] = max(current_size[0], largest_input_plus_output_size[0])
    first = True
    to_remove = {}
    for n in nx.topological_sort(corrected_workload):

        si = sum(n.operand_size_elem[I] * n.operand_precision[I] for I in n.input_operands if I not in n.constant_operands)

        # in node超过一个的话，就是residual层
        in_nodes = list(in_node for in_node, _ in corrected_workload.in_edges(n))
        in_nodes_num = len(in_nodes)

        if in_nodes_num == 2:
            # 有2个输入的话，一个放在residual buffer中，一个放在output buffer中，总大小除以2，两份等大的特征图
            si = sum(n.operand_size_elem[I] * n.operand_precision[I] for I in n.input_operands if I not in n.constant_operands) // 2
            # 首先减去前一层输出加上本层输入，因为可能要拼接overlap啥的，可能input要比前一层output大、
            add_to_size(-to_remove[in_nodes[1]][1])
            add_to_size(si)
            # 当前层的输出也要存储在片上
            s = n.operand_size_elem['O'] * n.operand_precision['O_final']

            del to_remove[in_nodes[1]]

            if n in permanent_data:
                add_to_size(permanent_data[n])

            for _, out_node in corrected_workload.out_edges(n):
                to_remove[n][0].append(out_node)
            to_remove[n][1] = s

        else:
            si = sum(n.operand_size_elem[I] * n.operand_precision[I] for I in n.input_operands if I not in n.constant_operands)
            # subtract existing, add this. Note that this is necessary as input may be greater than it was output of
            # a previous layer due to caching refetch
            # But reverse may also be true, because not all layers need all features generated by a previous layer
            # Thus take maximum  # TODO: that latter part.
            for in_node, _ in corrected_workload.in_edges(n):
                add_to_size(-to_remove[in_node][1])
            add_to_size(si)

            s = n.operand_size_elem['O'] * n.operand_precision['O_final']
            add_to_size(s)


            add_to_size(-si)

            # re add input part that was removed above because of overlap
            for in_node, _ in corrected_workload.in_edges(n):
                add_to_size(to_remove[in_node][1])

            for in_node, _ in corrected_workload.in_edges(n):
                to_remove[in_node][0].remove(n)
                if len(to_remove[in_node][0]) == 0:
                    add_to_size(-to_remove[in_node][1])
                    if n in permanent_data:
                        add_to_size(permanent_data[n])
                    del to_remove[in_node]

            to_remove[n] = [[], n.operand_size_elem['O'] * n.operand_precision['O_final']]
            for _, out_node in corrected_workload.out_edges(n):
                to_remove[n][0].append(out_node)
            to_remove[n][1] = s
    largest_input_plus_output_size = largest_input_plus_output_size[0]
    return largest_input_plus_output_size

def get_effective_output_to_cache(to_cache, node, make_caching):
    """
    - 计算每层需要cache的数据量
    - 需要根据tile size的推理决定

    From multiple required to_caches with lag, get the total to_cache with lag
    :param to_cache:
    :param node:
    :return:
    """
    # Q: 这个函数需要改什么？
    # A：应该不用改，暂时想不到。需要cache多少数据，数据库多大，都在to_cache中，由后续的推理tile 结构的函数负责
    # 这里只是根据某节点与其之后所有相连的节点，推理最大需要cache多少数据，overlap多少数据

    assert(node not in to_cache or not to_cache[node] or all(to_cache[node][i][0] == to_cache[node][next(iter(to_cache[node]))][0] for i in to_cache[node]))
    if node not in to_cache:
        return 0, 0
    if not to_cache[node]:
        return 0, 0
    lag = max(to_cache[node][i][2] for i in to_cache[node])     # 某个节点要提供的最大的块
    leftmost = min(to_cache[node][i][2] - to_cache[node][i][1] for i in to_cache[node])
    dim = to_cache[node][next(iter(to_cache[node]))][0]
    to_cache = lag-leftmost
    if not make_caching:
        to_cache = 0        # TODO: BETTER CHECK THIS CASE
    return dim, to_cache, lag

def backpropagate_tilesize(workload: DNNWorkload) \
        -> Tuple[List[LayerNode],
                 Dict[LayerNode, Tuple[str, int]],
                 Dict[Tuple[LayerNode, str], Tuple[str, int]],
                 Dict[LayerNode, Tuple[str, int]],
                 Dict[Tuple[LayerNode, str], Tuple[str, int]]]:
    """
    - 推理每一层每个tile的大小。以及行列方向需要cache的数据量.
    - Backpropagates a tilesize of (OX, OY) = (tile_x, tile_y) at the output nodes to (OX, OY) of earlier
    layers (nodes in workload).
    Note: all of this is for a fully-in-regime tile

    :param workload: the workload to apply this on
    :param tile_x:
    :param tile_y:
    :param use_horizontal_caching: assume horizontal caching is used
    :param use_vertical_caching: assume vertical caching is used
    :return: (usefull_nodes, overlap_columns_out, overlap_columns_in, overlap_rows_out, overlap_rows_in).
    First a list of nodes contributing to the output node currently handled (with index on_i).
    Then two both dicts containing for every layer how many columns if it's output/input should be cached
    for reuse.
    Then the same for rows
    - 首先是对当前处理的输出节点有贡献的节点列表(索引为on_i)。
    - 然后两个dict都包含每层的列数, 如果它的输出/输入应该被缓存以便重复使用。
    """
    # 修改内容：这个函数用来对网络的信息做一些初始化，根据tile size修正workload中的一些循环边界等信息
    # 一共用了四次：
    # 1. 用在整个workload上，计算每层完整的特征图
    # 2. 用在一个stack内，更新一个stack的信息
    # 3. 对一个stack 考虑cache的情况下，推导每个tile需要cache的数据量
    # 4. 用来算largest_input_plus_output_size
    # 这个函数还是要保留，因为1与正推或逆推没有关系，后面可以三次调用需要改成正着推

    # 函数说明：
    # 功能：从输出层逆推之前每一层的大小
    # 输入：完整的网络描述
    # 输出：（list）记录对输出节点有贡献的所有节点
    #       （dict）每一层的输入输出特征有多少应该被cache（行列各两个，一个表示输入，一个表示输出）

    on_i_list = [0]
    usefull_nodes_output_sizes = defaultdict(return_0_0_list)
    node_output_sizes_bits = {}
    columns_to_cache_output = defaultdict(return_empty_dict)  # of output!
    columns_to_cache_input = defaultdict(return_emtpystr_0_tuple)
    rows_to_cache_output = defaultdict(return_empty_dict)  # of output!
    rows_to_cache_input = defaultdict(return_emtpystr_0_tuple)
    # defaultdict 类：定义一个字典，如果查找的key不存在时，就为key默认赋值，赋值为括号里函数的返回值


    for on_i in on_i_list:
        # 从输出节点开始，每个stack只允许有一个输出节点,(用out_degree == 0 判断输出节点)
        on: LayerNode = list(node for node, out_degree in workload.out_degree() if out_degree == 0)[on_i]
        # 如果划了tile，就以tile size作为输出特征的大小


        # if tile_x is not None:
        #     on.loop_dim_size['OX'] = tile_x
        # if tile_y is not None:
        #     on.loop_dim_size['OY'] = tile_y
        usefull_nodes_output_sizes[on] = [on.loop_dim_size['OX'], on.loop_dim_size['OY']]
        nodes_to_trace_over = [(on, 'OX', 'OY', 0, 0)]

        # construct ROI of output patch (with usefull nodes)
        # largest_input_plus_output_size = 0
        while len(nodes_to_trace_over) > 0:
            # pop出一个节点开始计算
            n = nodes_to_trace_over.pop(0)   # pop(0): pop出列表的第一项，pop()默认为pop(-1)，即pop出列表的尾。 pop出后列表就少一项
            n, df_output_loop_X, df_output_loop_Y, lag_h, lag_v = n     # lag 代表啥意思？？？
            n.extract_layer_info()      # n 是 nodes_to_trace_over = [(on, 'OX', 'OY', 0, 0)] 中的on，是LayerNode类型
            # extract_layer_info()可以计算layernode的信息，包括total_MAC_count, operand_size_elem, operand_size_bit, operand_data_reuse

            # 计算节点的输出大小
            output_size = n.operand_size_elem['O'] * n.operand_precision['O_final']     # OFM size (HxWxK) * percison(8)
            node_output_sizes_bits[n] = output_size     # {layerndoe_OFM: 特征图数据量}，例如{LayerNode_2: OX*OY*K*8}

            # logger.debug(f'node {n} output size is below: ')
            # logger.debug(node_output_sizes_bits[n])

            # for input operands
            # get input operand source
            # 对他每个输入节点，计算需要缓存的数据量
            for I, input_node in n.input_operand_source.items():        # I: str, input_node: LayerNode
                input_loops = n.calc_tensor_dims(I, n.loop_dim_size)    # 当前node的输入特征图的维度，例如 {'C': 4, 'IX':5, 'IY':5}

                df_input_loop_X : str
                # 这里指的应该是residual 那种，OX同时是Input 和Output的索引
                if df_output_loop_X in input_loops:
                    df_input_loop_X = df_output_loop_X
                else:
                    # 不具有直接关系肯定有间接关系
                    for l in n.operand_loop_dim[I]['pr']:
                        if df_output_loop_X in n.operand_loop_dim[I]['pr'][l]:
                            df_input_loop_X = l     # 非残差的情况，df_input_loop_X设置为比如IX（对应了输出标识OX）
                            break

                df_input_loop_Y : str
                # Y轴同理
                if df_output_loop_Y in input_loops:
                    df_input_loop_Y = df_output_loop_Y
                else:
                    for l in n.operand_loop_dim[I]['pr']:
                        if df_output_loop_Y in n.operand_loop_dim[I]['pr'][l]:
                            df_input_loop_Y = l
                            break

                # find strides
                # 计算的步幅
                if df_input_loop_X == df_output_loop_X:     # add的情况，设置stride = 1
                    SX = 1
                else:
                    SX = n.pr_scaling_factors[df_input_loop_X][df_output_loop_X.lower()]
                if df_input_loop_Y == df_output_loop_Y:
                    SY = 1
                else:
                    SY = n.pr_scaling_factors[df_input_loop_Y][df_output_loop_Y.lower()]

                # 输入特征需要缓存的数据量
                # 数据 size - 索引 * stride。比如 size = 7，stride = 1， kernel size = 3， 那么for循环的索引应该是5，overlap是2
                input_overlap_X = max(0,
                                      input_loops[df_input_loop_X] - n.loop_dim_size[df_output_loop_X] * SX) # tile间overlap的大小
                input_overlap_Y = max(0,
                                      input_loops[df_input_loop_Y] - n.loop_dim_size[df_output_loop_Y] * SY)

                # find lag, newlag到底是啥？？？
                # lag表示的应该是总的数据块大小，lag - overlap是要cache的数据量？
                # 算出当前overlap所需的数据量 + 输入的overlap大小 - ？？
                newlag_h = SX * lag_h \
                           - (input_loops[df_input_loop_X] - n.loop_dim_size[df_output_loop_X] * SX + SX -1)//2 \
                           + input_overlap_X

                newlag_v = SY * lag_v \
                           - (input_loops[df_input_loop_Y] - n.loop_dim_size[df_output_loop_Y] * SY + SY -1)//2 \
                           + input_overlap_Y

                # 对I 这个输入特征图需要存储的大小      0：loop维度      1:overlap大小
                columns_to_cache_input[(n, I)] = df_input_loop_X, input_overlap_X
                rows_to_cache_input[(n, I)] = df_input_loop_Y, input_overlap_Y
                # 如果有cache，那么需要加载的数据量就可以减少，（overlap不需要重新加载）
                # if use_horizontal_caching:
                #     input_loops[df_input_loop_X] -= input_overlap_X
                # if use_vertical_caching:
                #     input_loops[df_input_loop_Y] -= input_overlap_Y
                # 更新IX 和 IY的维度
                IX = input_loops[df_input_loop_X]
                IY = input_loops[df_input_loop_Y]

                # 存储输入节点的输出特征作为当前节点输入的数据量
                # 看上去是更新了"usefull_nodes_output_sizes"这个dict, 本来是只有输出层特征，现在加入了输入层特征，变成了 {LayerNode_2: [3, 3], LayerNode_1: [5, 5]}
                # 下一次循环变成{LayerNode_2: [3, 3], LayerNode_1: [5, 5], LayerNode_0: [7, 7]}
                usefull_nodes_output_sizes[input_node][0] = max(
                    usefull_nodes_output_sizes[input_node][0],
                    IX)
                usefull_nodes_output_sizes[input_node][1] = max(
                    usefull_nodes_output_sizes[input_node][1],
                    IY)

                # 更新输入节点的loop dim size，即上一层的维度，例如{'B': 1, 'G': 4, 'OY': 5, 'OX': 5, 'FX': 3, 'FY': 3}
                input_node.loop_dim_size[n.operand_source_dimension_mapping[I][df_input_loop_X]] = \
                    usefull_nodes_output_sizes[input_node][0]
                input_node.loop_dim_size[n.operand_source_dimension_mapping[I][df_input_loop_Y]] = \
                    usefull_nodes_output_sizes[input_node][1]

                # 更新节点需要cache的数据量
                columns_to_cache_output[input_node][n] = [
                    n.operand_source_dimension_mapping[I][df_input_loop_X],
                    0,
                    newlag_h]

                # 返回的是当前输入节点需要满足后级需要的最大的大小（可能有多个输出，如residual结构）
                newlag_h = get_effective_output_to_cache(columns_to_cache_output, input_node, True)[2]

                rows_to_cache_output[input_node][n] = [
                    n.operand_source_dimension_mapping[I][df_input_loop_Y],
                    0,
                    newlag_v]
                newlag_v = get_effective_output_to_cache(rows_to_cache_output, input_node, True)[2]


                # 继续对输入节点重复上述推导操作
                if input_node in list(workload.nodes()):  # not true when stack cutting
                    nodes_to_trace_over.insert(0, (input_node,
                                                   n.operand_source_dimension_mapping[I][df_input_loop_X],
                                                   n.operand_source_dimension_mapping[I][df_input_loop_Y],
                                                   newlag_h,
                                                   newlag_v))

    # 返回：对当前节点有共享的所有节点，他们应该cache的输出特征列，他们输入特征需要cache的列
    return list(usefull_nodes_output_sizes.keys()), \
           {k: get_effective_output_to_cache(columns_to_cache_output, k, False)[:-1] for k in columns_to_cache_output}, \
           columns_to_cache_input, \
           {k: get_effective_output_to_cache(rows_to_cache_output, k, False)[:-1] for k in rows_to_cache_output}, \
           rows_to_cache_input


def forwardpropagete_tilesize(workload: DNNWorkload, tile_x, tile_y,
                              first_x = False, first_y = False,
                              last_x = False, last_y = False,
                              use_horizontal_caching = False,
                              make_horizontal_caching = False) \
                              -> Tuple[
                                  List[LayerNode],
                                  Dict[LayerNode, Tuple[str, int]],
                                  Dict[Tuple[LayerNode, str], Tuple[str, int]]
                              ]:
    on_i_list = [0]
    usefull_nodes_output_sizes = defaultdict(return_0_0_list)
    node_output_sizes_bits = {}
    # 对InputLayerNode， 这个应该没有
    columns_to_cache_output = defaultdict(return_empty_dict)  # of output!
    columns_to_cache_input = defaultdict(return_emtpystr_0_tuple)
    rows_to_cache_output = defaultdict(return_empty_dict)  # of output!
    rows_to_cache_input = defaultdict(return_emtpystr_0_tuple)

    # 首先，正着推X
    # stack 内的InputLayerNode可能有多个，但outputNode只能有一个
    in_node_list = list(node for node, in_degree in workload.in_degree() if in_degree == 0)
    logger.debug('X Y size inference.')
    # input_layer_node:
    # x: 第一个tile是128，之后是128（输入是128，但是计算的时候要拼接上overlap？），最右边是剩余的大小
    # y：先设置的大一点，因为目前的stack cut逻辑不能保证stack cut之后输出层有一行
    for in_node in in_node_list:
        if tile_x is not None:
            in_node.loop_dim_size['OX'] = tile_x
        if tile_y is not None:
            in_node.loop_dim_size['OY'] = tile_y
        usefull_nodes_output_sizes[in_node] = [in_node.loop_dim_size['OX'], in_node.loop_dim_size['OY']]
        in_node.extract_layer_info()
        nodes_to_trace_over = [(in_node, 'OX', 'OY', 0, 0)]

        while len(nodes_to_trace_over) > 0:
            n: LayerNode = nodes_to_trace_over.pop(0)
            n, df_output_loop_X, df_output_loop_Y, lag_h, lag_v = n
            successor_of_cur_node = [out_node for _, out_node in workload.out_edges(n)]
            for s_node in successor_of_cur_node:
                # 首先找到当前节点在后续节点的位置
                edge_info = [('I', 0)]
                for I, input_node in s_node.input_operand_source.items():
                    if input_node.id == n.id:
                        edge_info = I, input_node
                        break

                # 更新successor节点的OX
                # 1. 如果successor是个residual，那么OX和OY不减小
                # 2. 如果successor是个conv，那么OX和OY应该是要变为IX - kernel_size + 1

                #### 1.1 residual
                if [s_node.memory_operand_links[I] for I in s_node.input_operands] == ['R', 'I1']:
                    s_node.loop_dim_size['OX'] = n.loop_dim_size['OX']
                    s_node.loop_dim_size['OY'] = n.loop_dim_size['OY']
                else:
                    ### 1.2 conv，首先，如果不是每列第一块，那么需要拼接上overlap才是下一层的输入
                    ######## 第一块的标记：use_horizontal_caching

                    # 第一步，确定idx间的映射关系
                    input_loops = s_node.calc_tensor_dims(edge_info[0], s_node.loop_dim_size)
                    df_input_loop_X: str
                    if 'OX' in input_loops:
                        df_input_loop_X = df_output_loop_X
                    else:
                        for l in s_node.operand_loop_dim[I]['pr']:
                            if 'OX' in s_node.operand_loop_dim[I]['pr'][l]:
                                df_input_loop_X = l
                                break
                    df_input_loop_Y: str
                    if df_output_loop_Y in input_loops:
                        df_input_loop_Y = df_output_loop_Y
                    else:
                        for l in s_node.operand_loop_dim[I]['pr']:
                            if df_output_loop_Y in s_node.operand_loop_dim[I]['pr'][l]:
                                df_input_loop_Y = l
                                break

                    # 确定stride，这样才能确定output的大小
                    if df_input_loop_X == df_output_loop_X:
                        SX = 1
                    else:
                        SX = s_node.pr_scaling_factors[df_input_loop_X][df_output_loop_X.lower()]

                    if df_input_loop_Y == df_output_loop_Y:
                        SY = 1
                    else:
                        SY = s_node.pr_scaling_factors[df_input_loop_Y][df_output_loop_Y.lower()]

                    # 确定kernel size
                    if 'FX' in s_node.loop_dim_size:
                        k = s_node.loop_dim_size['FX']
                    else:
                        k = 1

                    # 确定overlap大小
                    if 'FX' in s_node.loop_dim_size:
                        input_overlap_X = max(0,
                                              s_node.loop_dim_size['FX'] - SX)
                    else:
                        input_overlap_X = 0
                    input_overlap_Y = max(0,
                                          input_loops[df_input_loop_Y] - s_node.loop_dim_size[df_output_loop_Y] * SY)

                    # 确定新的loop size
                    newlag_h = SX * lag_h

                    newlag_v = SY * lag_v \
                            - (input_loops[df_input_loop_Y] - s_node.loop_dim_size[df_output_loop_Y] * SY + SY -1) // 2 \
                            + input_overlap_Y

                    IX = input_loops[df_input_loop_X]
                    IY = input_loops[df_input_loop_Y]

                    usefull_nodes_output_sizes[s_node][0] = max(
                        usefull_nodes_output_sizes[s_node][0],
                        IX)

                    left_pad = k // 2 if first_x else 0
                    right_pad = k // 2 if last_x else 0
                    top_pad = k // 2 if first_y else 0
                    bottom_pad = k // 2 if last_y else 0
                    pad_lr = left_pad + right_pad
                    pad_tb = top_pad + bottom_pad

                    columns_to_cache_input[(s_node, I)] = df_input_loop_X, input_overlap_X
                    # X 方向，要拼接上pad
                    if not use_horizontal_caching:
                        # 最左侧块正常缩减
                        # （前一层的输出size - 当前层kernelsize）/ stride
                        s_node.loop_dim_size['OX'] = min((n.loop_dim_size[df_output_loop_X] + pad_lr - k) // SX + 1, s_node.loop_dim_size['OX'])
                    else:
                        # 其余块拼接overlap后缩减，overlap的大小是successor的kernel_size - SX
                        s_node.loop_dim_size['OX'] = min((n.loop_dim_size[df_output_loop_X] + pad_lr - SX) // SX + 1, s_node.loop_dim_size['OX'])

                    # Y 方向
                    # 每次减少kernel size - 1 行
                    s_node.loop_dim_size['OY'] = min((n.loop_dim_size['OY'] + pad_tb - k + 1) // SY, s_node.loop_dim_size['OY'])

                    columns_to_cache_output[n][s_node] = [
                        s_node.operand_source_dimension_mapping[I][df_input_loop_X],
                        input_overlap_X if make_horizontal_caching else 0,
                        newlag_h
                    ]
                    newlag_h = get_effective_output_to_cache(columns_to_cache_output, n, True)[2]
                    logger.debug("node id: " + str(s_node.id))
                    logger.debug("OY: "+ str(s_node.loop_dim_size['OY']) + "And OX: "+ str(s_node.loop_dim_size['OY']))
                    s_node.extract_layer_info()

                    if s_node in list(workload.nodes()):    # not True when stack cutting
                        nodes_to_trace_over.insert(
                            0, (s_node,
                                s_node.operand_source_dimension_mapping[I][df_input_loop_X],
                                s_node.operand_source_dimension_mapping[I][df_input_loop_Y],
                                newlag_h,
                                newlag_v))

    return list(usefull_nodes_output_sizes.keys()), \
            {k: get_effective_output_to_cache(columns_to_cache_output, k, make_horizontal_caching)[:-1] for k in columns_to_cache_output}, \
            columns_to_cache_input

def get_y_stride(workload: DNNWorkload):
    output_node: LayerNode = list(node for node, out_degree in workload.out_degree() if out_degree == 0)[0]
    return output_node.loop_dim_size['OY']


class DepthFirstStage_ME(Stage):
    """
    Stage that processes a workload in a depth first style manner.
    Yielded results are per-layer accumulated results across tiles.
    Subcallable may only yield a single value!
    """
    def __init__(self, list_of_callables, *,
                 accelerator,
                 workload: DNNWorkload,
                 df_tilesize_x:int, df_tilesize_y:int,
                 df_horizontal_caching:bool, df_vertical_caching:bool,
                 df_stack_cuts:list,
                 **params):
        """
        Initialize the pipeline by initializing the workload and spatial mapping converison loma pipelines.
        :param main_inputs: MainInputs, NOT copied
        """
        super().__init__(list_of_callables, **params)
        self.tilesize_x = df_tilesize_x
        self.tilesize_y = df_tilesize_y
        self.horizontal_caching = df_horizontal_caching
        self.vertical_caching = df_vertical_caching
        self.workload = workload
        self.accelerator = accelerator
        self.df_stack_cuts = df_stack_cuts

    def __str__(self):
        return str(type(self).__name__)

    def __repr__(self):
        return str(self)

    def run(self):

        nb_workload_output_nodes = \
            len(list(node for node, out_degree in self.workload.out_degree() if out_degree == 0))

        cost_model_evaluations_per_layer = defaultdict(return_empty_list)
        first_input = next(self.workload.topological_sort())

        ########################################################
        #= 第一阶段：首先按照DFcutStage阶段的划分，将计算图分割为子图，并在子图插入一个InputLayerNode
        #= 第二阶段：对每个stack
        #=          1. 确定cache数据的大小和位置
        #=          2. 确定了cache数据的位置，就开始实际评估每个tile的开销，除了cache数据的位置，IWO等是在此处尝试安排在mem上的
        #=   需要的辅助函数：
        #=   1. 评估每个tile的开销，这里还有数据移动操作，residual的处理就靠这个函数了
        #=   2. 确定每个tile的cache数据的位置
        ########################################################

        # compute full feature map sizes first
        # backpropagate_tilesize(self.workload, None, None, False, False, False, False)
        # first_input = next(self.workload.topological_sort())

        ##########################################################
        #= 第一阶段
        #= stack子图划分，inputlayerndoe插入
        #= split into substacks, 下面的这个 for loop 就是真正切分stack的，
        # 上一个stage生成了要在哪里切的列表，在这里真正的把DNN图切成子图，切开的部分要添加一个“头”，叫"InputLayerNode_substack_input_layer_0"
        #
        ##########################################################
        substacks = []  # items: [DNNWorkload, last_node_before=node that generates input and not included, last_node = node that generates output and included] Later each appended with ml for input and ml for output
        cut_before: LayerNode or MemNode
        cut_after: LayerNode or MemNode
        for cut_before, cut_after in zip([None] + self.df_stack_cuts, self.df_stack_cuts + [None]):  # works with empty list of df_stack_cuts
            logger.debug('cut before: ' + str(cut_before) + 'And cut after: '+ str(cut_after))
            if cut_before == list(self.workload.topological_sort())[-1].id:
                continue

            substack: DNNWorkload = pickle_deepcopy(self.workload)
            # remove everything before
            if cut_before:  # is not None:
                final = substack.get_node_with_id(cut_before)
                last_added = [final]
                all_predecessors = [final]
                while last_added:
                    last_added_cp = last_added[:]
                    last_added.clear()
                    for p in last_added_cp:
                        last_added.extend(list(substack.predecessors(p)))
                    all_predecessors.extend(last_added)


                # 移除cut before节点和其之前所有的节点（他的所有输入）
                # 转换成set 去重
                for p in set(all_predecessors):
                    substack.remove_node(p)

                # 获得cut before 节点之后的所有节点（所有输出和输出的输出）
                all_successors_of_final = [n.id for n in self.workload.successors(self.workload.get_node_with_id(cut_before))]
            else:   # 如果不用cut before
                # 此时stack的第一个节点一定是input node
                first_node = list(substack.topological_sort())[0]
                if not isinstance(first_node, InputLayerNode):
                    assert False, "First node of workload is not an InputLayerNode"
                    #all_successors_of_final = [first_node.id]
                    #first_node.input_operand_source['I'] = first_node
                else:
                    all_successors_of_final = None

            # 在切开的部分插入InputLayerNode
            if all_successors_of_final:
                sil_counter = 0
                input_nodes = set()
                for n in all_successors_of_final:
                    input_nodes.update(self.workload.get_node_with_id(n).input_operand_source.values())

                # 对所有节点的输入，用set去重
                input_nodes = {n for n in input_nodes if n.id not in list(nn.id for nn in substack.nodes()) }

                # 这是根据映射关系，计算当前层的输出，需要多大的输入，这是input tensor
                # 输入是前一层的输出，具有不同映射关系
                for n in input_nodes:
                    input_loop_dim_sizes = {}
                    input_precision = 0
                    for i in all_successors_of_final:
                        s:LayerNode = substack.get_node_with_id(i)
                        for k, v in s.input_operand_source.items():
                            if v.id == n.id:
                                input_dims = s.calc_tensor_dims(k, s.loop_dim_size)
                                for d, dsize in input_dims.items():
                                    d = s.operand_source_dimension_mapping[k][d]
                                    if d in ['C', 'K', 'G']:
                                        input_loop_dim_sizes[d] = min(input_loop_dim_sizes.get(d,1000000000000), dsize)
                                    else:
                                        input_loop_dim_sizes[d] = max(input_loop_dim_sizes.get(d,0), dsize)
                                input_precision = max(input_precision, s.operand_precision[k])

                    # 已经计算出的input数据大小，插入input layer node，代替计算图被切分的输入
                    new_input_node = InputLayerNode(f'substack_input_layer_{sil_counter}', input_loop_dim_sizes, input_precision, first_input.memory_operand_links, first_input.core_allocation)
                    substack.add_node(new_input_node)
                    for i in all_successors_of_final:
                        s:LayerNode = substack.get_node_with_id(i)
                        for k, v in list(s.input_operand_source.items()):
                            if v.id == n.id:
                                s.input_operand_source[k] = new_input_node
                                substack.add_edge(new_input_node, s)
                    # sil：stack input layer？ 反正指的是input layer node节点的序号
                    sil_counter += 1

            # remove everything after
            # 已经删除了cut before 及之前的所有节点，接下来删除cut after之后的所有节点，cut after节点会被保留
            if cut_after:   # is not None:
                start = substack.get_node_with_id(cut_after)
                last_added = list(substack.successors(start))
                all_successors = last_added[:]
                while last_added:
                    last_added_cp = last_added[:]
                    last_added.clear()
                    for p in last_added_cp:
                        last_added.extend(list(substack.successors(p)))
                    all_successors.extend(last_added)
                # set去重
                for s in set(all_successors):
                    substack.remove_node(s)

            # 只是删除predecessors 和 successors之后，可能会有浮空的节点（比如带菱形的网络结构，会有两个节点在同一个level）
            # remove floating parallel (other branches) pieces
            to_keep = []
            # 有效的输出节点是cut after 标记的节点，或者是整个网络的最后一层
            endnodes = [substack.get_node_with_id(cut_after) if cut_after else list(substack.topological_sort())[-1]]
            to_keep.extend(endnodes)
            while endnodes:
                endnodes = sum((list(substack.predecessors(n)) for n in endnodes), [])
                to_keep.extend(endnodes)
            for n in list(substack.nodes()):
                if n not in to_keep:
                    substack.remove_node(n)

            # 完成一次分割之后，记录下分割的子图
            substacks.append([substack, cut_before, cut_after])
        logger.info(f'Stack Cut Finished, cut whole workload into {len(substacks)} stacks.')
        #     from visualization.graph.dnn import visualize_dnn_graph
        #     visualize_dnn_graph(substack)
        # #= 好了，子图都切完了
        # exit()

        ################################################################
        #= 第二阶段：评估每个stack中的每层的每个layer的每个tile
        ################################################################
        ########################################################
        # figure out where the feature maps in between stacks go
        #= 2.1： stack 间采用DRAM进行数据交互
        #= 决定 stack 间的数据通信，使用DRAM 作为中转
        ########################################################
        # NOTE: can not just take the ml that the feature map fits in,
        # as while it is being computed, that ml might also be needed for processing
        #Therefore, for now we just take dram

        mh : MemoryHierarchy = self.accelerator.get_core(next(n for n in nx.topological_sort(self.workload) if hasattr(n, 'core_allocation')).core_allocation ).memory_hierarchy
        # I1 一般是给输入的，o 一般是给输出的，I2一般给权重
        # DRAM 是WIO通用的，所以 -1 指的就是DRAM层

        for ss in substacks:
            ss.append(mh.get_memory_levels('I1')[-1])
            ss.append(mh.get_memory_levels('O')[-1])

        # with open('substack.py', 'w') as fff:
        #     for i in substacks:
        #         print(i,file=fff)
        # exit()

        ###########################################################
        #= 2.2： 逐stack逐layer逐tile进行评估
        #= 这个 for loop: 接下来对每个stack中的每层每个 tile 进行评估
        ###########################################################
        for substack, cut_before, cut_after, input_ml, output_ml in substacks:
            usefull_workload = pickle_deepcopy(substack)

            # usefull nodes指的是输出节点，一个stack内不应该有两个输出
            usefull_nodes = list(node for node, out_degree in usefull_workload.out_degree() if out_degree == 0)
            assert len(usefull_nodes) == 1, "DepthFirstStage does not support workloads (or substacks) with multiple outputs"

            # 选择输出节点
            on = usefull_nodes[0]

            input_nodes = list(node for node, in_degree in usefull_workload.in_degree() if in_degree == 0)
            inode = input_nodes[0]

            total_OX, total_OY = inode.loop_dim_size['OX'], inode.loop_dim_size['OY']
            # 记录下不同tile的执行结果， 方便查询，避免重复调用cost model
            run_for_tilesize_cache = {}

            ###############################################################################
            #= 定义评估一个tile的开销的方法
            # 1. 尝试安排IO mem级别，不够就不断加，直到能够安排下for 循环
            # 2. 建模数据移动操作，CI -> I, O -> CO, O -> I
            # 3. 要加一个R -> I
            # 4. 安排好了之后调costmodel
            #################################################################################
            def run_for_tilesize(tile_x, tile_y, weights_from_top,
                                 first_x, first_y,
                                 last_x, last_y,
                                 make_horizontal_cache_ml   =None,
                                 use_horizontal_cache_ml    =None,
                                 horizontal_write_columns   =None,
                                 horizontal_read_columns    =None,
                                 w_ml   =None,
                                 tile_x0=None, tile_y0=None) -> dict: #only for info printing
                # caching results for runtime optimization
                args = (tile_x, tile_y, weights_from_top, first_x, first_y, last_x, last_y,
                        make_horizontal_cache_ml, use_horizontal_cache_ml,
                        tuple(horizontal_write_columns.items()), tuple(horizontal_read_columns.items()))

                # 如果相同的tile已经评估过，直接返回结果
                if args in run_for_tilesize_cache:
                    return run_for_tilesize_cache[args]

                # not in cache => actually computing this tile
                # 如果没有评估过，那么计算tile
                logger.debug("Running for " + str(tuple(a if not isinstance(a, MemoryLevel) else a.memory_instance.name for a in args)) + f"at position {tile_x0}, {tile_y0}")

                # 结果保存
                best_cme_per_layer_tile = {}
                usefull_workload_tile = pickle_deepcopy(usefull_workload)

                # 更新usefull workload tile里的信息
                usefull_nodes, _, _= forwardpropagete_tilesize(usefull_workload_tile, tile_x, tile_y, first_x, first_y, last_x, last_y,
                                                                  use_horizontal_caching=use_horizontal_cache_ml is not None,
                                                                  make_horizontal_caching=make_horizontal_cache_ml is not None)


                mh = self.accelerator.get_core(next(n for n in nx.topological_sort(usefull_workload_tile) if hasattr(n, 'core_allocation')).core_allocation).memory_hierarchy

                # 确定weight buffer应该存储的位置
                memories_to_take_for_W = []
                # 到指定级别之前的都加入到 w_ml中
                if w_ml is not None:
                    for i, ml in enumerate(mh.get_memory_levels(next(n for n in nx.topological_sort(usefull_workload_tile) if hasattr(n, 'memory_operand_links') and 'W' in n.memory_operand_links).memory_operand_links['W'])):
                        memories_to_take_for_W.append(ml)
                        if ml == w_ml:
                            break


                # 确定输入的来源
                # 1. 之前一层tile的输出
                # 2. 上一次计算stack cache在mem中的数据

                # lookup dictionary to know where a previous layer stored its output
                # to know where to find the input at a current layer
                # 有专门的表记录上一层tile存储的位置
                memories_to_take_for_I_lookup_as_from_O = {}

                # run the newly adapted workload
                # 记录下获取输入所需的数据移动操作
                to_copy = []  # holds still to proces DataMoveActions
                layer : LayerNode or MemNode
                has_input = False
                for layer in usefull_workload_tile.topological_sort():
                    orig_layer = layer

                    # throwing stuff at the wall to see what sticks
                    # 因为不能确定数据能不能放得下，所以是尝试当前mem结构是否足够，不够就加mem级别
                    extra_output_memlevels_because_it_did_not_work = 0
                    extra_input_memlevels_because_it_did_not_work = 0
                    to_copy_orig = to_copy[:]

                    while True:  # serves more as a goto target here
                    # 开始尝试安排当前tile的数据
                        # 首先备份一下layer ndoe
                        layer = orig_layer
                        logger.debug(f"Current layer: {layer}")

                        # 输入节点入度为0，输入节点一定是InputLayerNode
                        is_substack_input = usefull_workload_tile.in_degree(layer) == 0
                        assert(not is_substack_input or isinstance(layer, InputLayerNode)), "Found a layernode that has no incoming edge but is not an input. Check input_operand_source"
                        # 输出节点出度为0
                        is_substack_output = usefull_workload_tile.out_degree(layer) == 0

                        # 因为当前的mem安排不一定成功，所以先备份一个to copy
                        to_copy = to_copy_orig[:]
                        layer = pickle_deepcopy(layer)

                        residual_buffer = []

                        # 优先级 I > O > H cache > V cache > W
                        # 首先安排输入
                        if is_substack_input:  # until the one decided for this substack
                            # layerInputNode 是将数据从DRAM搬到O buffer， 所以不需要确定I buffer的级别
                            memories_to_take_for_I = [None]
                        else:
                            # 首先确定输入的大小
                            # 这里的I 指的是WL，py里equation 中 = 之后的部分
                            input_size = sum(layer.operand_size_elem[I] * layer.operand_precision[I] for I in layer.input_operands if I not in layer.constant_operands)
                            # TODO: better way to get relevant input operands?
                            #  If so, do on lot's of places in this file
                            if [layer.memory_operand_links[I] for I in layer.input_operands] == ['R', 'I1']:
                                logger.debug('residual layer, the input feature are reduced by half because half of them are in the residual buffer.')
                                input_size = input_size // 2
                                input_list = [I for I in layer.input_operands if I not in layer.constant_operands]
                                I = input_list[0]
                                logger.debug('add residual buffer.')
                                for i, ml in enumerate(mh.get_memory_levels(layer.memory_operand_links[I])):
                                    residual_buffer.append(ml)
                                logger.debug('Input size: ' + str(input_size))
                                memories_to_take_for_I = []
                                I = input_list[1]
                                for i, ml in enumerate(mh.get_memory_levels(layer.memory_operand_links[I])):
                                    memories_to_take_for_I.append(ml)
                                    if ml.memory_instance.size >= input_size and ml.unroll_count == 1:
                                        break
                            else:
                                logger.debug("Input size: " + str(input_size))

                                # loweset ml that fits all the inputs of this layer and is not unrolled
                                # 最低I 级别是能放下所有input而且没被unroll
                                memories_to_take_for_I = []
                                I = next(I for I in layer.input_operands if I not in layer.constant_operands)

                                # ？？为啥不用循环
                                # 确实不用，conv的话只有I，residual都是存在I1 mem里
                                for i, ml in enumerate(mh.get_memory_levels(layer.memory_operand_links[I])):
                                    memories_to_take_for_I.append(ml)
                                    if ml.memory_instance.size >= input_size and  ml.unroll_count == 1:
                                        break

                        # 计算输出特征大小
                        layer_output_size = layer.operand_size_elem['O'] * layer.operand_precision['O_final']
                        logger.debug("Output size elem: " + str(layer.operand_size_elem))
                        logger.debug('Output size: ' + str(layer_output_size))

                        # 安排输出特征存储
                        if is_substack_output:  # just take all of them
                            # stack的输出节点直接输出到DDR
                            memories_to_take_for_O = []
                            for i, ml in enumerate(mh.get_memory_levels(layer.memory_operand_links['O'])):
                                memories_to_take_for_O.append(ml)
                                if ml == output_ml:
                                    break
                        else:
                            # 寻找能存储output的最低级别
                            # 1. 能存下output
                            # 2. 如果是IO共享的buffer，是I的最高级的话，还要能存下所有的I
                            # 3. 并且不能是unroll的

                            # lowest ml that fits
                            # - the output
                            # - the input, if this ml is also the highest one to be included for inputs
                            #  ... and is not unrolled
                            memories_to_take_for_O = []
                            for i, ml in enumerate(mh.get_memory_levels(layer.memory_operand_links['O'])):
                                memories_to_take_for_O.append(ml)
                                if ml.memory_instance.size >= layer_output_size + \
                                        (input_size if memories_to_take_for_I[-1] == ml else 0) and ml.unroll_count == 1:
                                    break

                        # extra_input(output)_memlevels_because_it_did_not_work 是用来确定要额外追加多少级mem
                        # ？？？？什么原因导致存不下，已经计算了所有的size，应该能存下
                        # throwing this at wall stuff: take more levels if already proven that more are needed
                        if extra_input_memlevels_because_it_did_not_work:
                            memories_to_take_for_I.extend(mh.get_memory_levels(layer.memory_operand_links[next(I for I in layer.input_operands if I not in layer.constant_operands)])[len(memories_to_take_for_I):len(memories_to_take_for_I)+extra_input_memlevels_because_it_did_not_work])
                        if extra_output_memlevels_because_it_did_not_work:
                            memories_to_take_for_O.extend(mh.get_memory_levels(layer.memory_operand_links['O'])[len(memories_to_take_for_O):len(memories_to_take_for_O)+extra_output_memlevels_because_it_did_not_work])

                        logger.debug('top to take for I  {}'.format(memories_to_take_for_I[-1]))

                        # register to_copy stuff (DataCopyActions to be)
                        # 分配了mem之后，开始收集输入数据（输入所在mem -> input mem的最高级别）
                        if is_substack_input:   # stack的输入节点，从DRAM版数据到O的最高级别
                            # 这里如果是residual的话，需要一个搬运到O buffer，一个搬运到residual buffer
                            # For the InputLayerNode, we just add a to copy action to copy from stack input memory level to a lower memory level
                            # That is all it has to do. Code as per usual already computes the size of this new patch,
                            # As well as how many cached inputs to refetch (for the next layer) from the caching ml
                            if not has_input:
                                to_copy.append((('SI', 'O'), input_ml, memories_to_take_for_O[-1], layer.operand_size_bit['O']))
                                logger.debug("Added to copy stack input -> input: " + str(tuple(a if not isinstance(a, MemoryLevel) else a.memory_instance.name for a in to_copy[-1])))
                                has_input = True
                            else:
                                to_copy.append((('SI', 'R'), input_ml, residual_buffer[-2], layer.operand_size_bit['O']))
                                logger.debug("Added to copy stack input -> residual: " + str(tuple(a if not isinstance(a, MemoryLevel) else a.memory_instance.name for a in to_copy[-1])))

                        else:
                            # output -> input
                            # 不是输入节点的话，就要从前一层的输出块收集数据

                            # 这里又要识别residual层，做额外的处理了，先把I2都删了，然后把residual标记为I2，然后两个输入之一来自residual buffer
                            # 写回的时候也要注意，同时往output buffer和residual buffer写

                            if [layer.memory_operand_links[I] for I in layer.input_operands] == ['R', 'I1']:
                                # 为了简化难度，限制在WL描述文件中，X表示离得较远的输入，存在residual buffer中，Y表示离得较近的输入，存在output buffer中
                                # O -> I, R -> I
                                # 较远的输入，从residual buffer中获取

                                # 获取前一层的输出
                                I2 = layer.input_operand_source['Y']
                                stored_as_output = memories_to_take_for_I_lookup_as_from_O[I2.id]
                                # 什么时候需要收集数据：1. 首先不是Input Layer Node，并且当前I lv不是前一层的O lv 2，是输入节点，但是前一层的输出不在I lv的任意一级
                                if memories_to_take_for_I[-1] != stored_as_output[0] and not isinstance(I2, InputLayerNode) \
                                        or stored_as_output[0] not in memories_to_take_for_I and isinstance(I2, InputLayerNode):
                                    to_copy.append((('O', 'Y'), stored_as_output[0], memories_to_take_for_I[-1], stored_as_output[1]))
                                    logger.debug('Added to copy output -> input: ' + str(tuple(a if not isinstance(a, MemoryLevel) else a.memory_instance.name for a in to_copy[-1])))
                            else:
                                for I in layer.input_operand_source:
                                    stored_as_output = memories_to_take_for_I_lookup_as_from_O[layer.input_operand_source[I].id]
                                    # 什么时候需要收集数据：1. 首先不是InpuLayerNode 并且当前I lv不是前一层的o lv   2. 是输入节点，但前一层的输出不在I lv的任意一级
                                    if memories_to_take_for_I[-1] != stored_as_output[0] and not isinstance(layer.input_operand_source[I], InputLayerNode) \
                                            or stored_as_output[0] not in memories_to_take_for_I and isinstance(layer.input_operand_source[I], InputLayerNode):
                                        # the inputs where not stored where they need to be stored now -> copy them
                                        # 为什么需要情况2？？ 输入节点不就是从DDR移动到0吗。。。又可能这层的输入是InputLayerNode，他本身最高的mem级别也是DRAM
                                        to_copy.append((('O', I), stored_as_output[0], memories_to_take_for_I[-1], stored_as_output[1]))
                                        logger.debug("Added to copy output -> input: " + str(tuple(a if not isinstance(a, MemoryLevel) else a.memory_instance.name for a in to_copy[-1])))

                                # 如果有cache 住的overlap数据，那么还需要把这些数据移动出来
                                # 首先是行方向cache的数据
                                # caches for horizontal resue -> input
                                if use_horizontal_cache_ml is not None and use_horizontal_cache_ml != memories_to_take_for_I[-1]:
                                    for I in layer.input_operands:
                                        if I not in layer.constant_operands:
                                            # copy cached inputs
                                            amount_bits_factors = {k: layer.loop_dim_size[k] for k in layer.operand_loop_dim[I]['r']}
                                            for k in layer.operand_loop_dim[I]['pr']:
                                                amount_bits_factors[k] = layer.calc_tensor_dims(I, layer.loop_dim_size)[k]
                                            # 这个horizontal里存的是什么？
                                            amount_bits_factors[horizontal_read_columns[(layer.id, I)][0]] = horizontal_read_columns[(layer.id, I)][1]
                                            amount_bits_factors['precision'] = layer.operand_precision['O_final']

                                            # practically doing this but more flexible in terms of loops and operand names
                                            # amount_bits_factors = horizontal_read_columns[layer.id] \
                                            #                       , LayerNode.return_lambda(layer.pr_funcs_LUT['IY'])(layer.loop_dim_size) \
                                            #                       , layer.loop_dim_size.get('C', 1) \
                                            #                       , layer.operand_precision['I']
                                            amount_bits = prod(amount_bits_factors.values())
                                            if amount_bits>0:
                                                to_copy.append((('CI',I), use_horizontal_cache_ml, memories_to_take_for_I[-1], amount_bits))
                                                logger.debug("Added to copy cached input (H) -> input: " + str(tuple(a if not isinstance(a, MemoryLevel) else a.memory_instance.name for a in to_copy[-1])) + " = " + '*'.join(str(f) for f in amount_bits_factors.values()))

                        # 已经准备好了输入数据，现在开始研究输出怎么办
                        # give subsequent layers info on where to find there inputs = outputs of this layer
                        memories_to_take_for_I_lookup_as_from_O[layer.id] = memories_to_take_for_O[-1], layer_output_size

                        logger.debug('Top to take for O  {}'.format(memories_to_take_for_O[-1]))

                        # copy of the accelerator, which will have adjusted memory hierarchy
                        # 因为cost model 只能从最顶层mem 搬数据，所以删掉多余的mem结构，然后再扔给cost model
                        accelerator_mem_level_removed = pickle_deepcopy(self.accelerator)
                        accelerator_mem_level_removed.name += "_sub"
                        # the memory hierarchy that will be adjusted
                        memhier = accelerator_mem_level_removed.get_core(layer.core_allocation).memory_hierarchy



                        # We now know which memory levels to include, remove everything above it
                        # 非Input Node的话，是可能有多余的input mem结构，移除
                        ## 这里保留下residual buffer，别被删了
                        if not is_substack_input:
                            for I in layer.input_operands:
                                if I not in layer.constant_operands and I != 'R':
                                    while memories_to_take_for_I[-1] not in memhier.get_operator_top_level(layer.memory_operand_links[I])[0]:

                                        removed, _ = memhier.remove_operator_top_level(layer.memory_operand_links[I])
                                        accelerator_mem_level_removed.get_core(layer.core_allocation). \
                                            recalculate_memory_hierarchy_information()

                        # 如果不是输出节点的话，是可能存在多余的output mem结构，移除
                        if not is_substack_output:
                            while memories_to_take_for_O[-1] not in memhier.get_operator_top_level(layer.memory_operand_links['O'])[0]:

                                removed, _ = memhier.remove_operator_top_level(layer.memory_operand_links['O'])
                                accelerator_mem_level_removed.get_core(layer.core_allocation). \
                                    recalculate_memory_hierarchy_information()


                        # Adapt the memory stack for 'layers' like 'add' where two operands come from the same part of the
                        # Memory hierarchy. In this case, I2 is removed completely, and then everywhere I1 is present, I2
                        # is also made present and one of the two layer operands is mapped to I2
                        # 对residual层，没有I2，删掉所有与I2有关的mem
                        if [layer.memory_operand_links[I] for I in layer.input_operands] == ['R', 'I1']:
                            while memhier.remove_operator_top_level('I2')[0]:
                                pass
                            for ml in memhier.nodes:
                                if 'R' in ml.operands:
                                    # 直接标记为I1和I2公用
                                    ml.operands.append('I2')
                                    ml.mem_level_of_operands['I2'] = ml.mem_level_of_operands['R']
                                    l = list(ml.port_alloc_raw)
                                    l.append(ml.port_alloc_raw[ml.operands.index('R')].copy())
                                    ml.port_alloc_raw = tuple(l)
                                    for p in (ml.port_list):
                                        for sold in p.served_op_lv_dir[:]:
                                            if sold[0] == 'R':
                                                p.add_port_function(tuple(['I2'] + list(sold[1:])))

                            # 把workload描述中的第二个I1 改成I2，这样好区分两个不同的输入特征
                            memhier.nb_levels['I2'] = memhier.nb_levels['R']
                            layer.memory_operand_links[layer.input_operands[1]] = 'I2'
                            accelerator_mem_level_removed.get_core(layer.core_allocation).recalculate_memory_hierarchy_information()
                            copied_I1 = True
                            logger.debug('residual layer. change R to I2')
                        else:
                            copied_I1 = False

                        # remove too high weight memory levels
                        # 最后，安排权重
                        if not weights_from_top:
                            if layer.constant_operands:
                                if memories_to_take_for_W:
                                    while memories_to_take_for_W[-1] not in memhier.get_operator_top_level(layer.memory_operand_links[layer.constant_operands[0]])[0]:
                                        removed, _ = memhier.remove_operator_top_level(layer.memory_operand_links['W'])
                                        accelerator_mem_level_removed.get_core(layer.core_allocation). \
                                            recalculate_memory_hierarchy_information()
                                else:
                                    # LINYAN: there are no weights => okay to leave memory hierarchy of non-existent weight operand?
                                    pass

                        # process still to process DataMoveActions
                        # 继续处理数据移动操作
                        to_copy_actions = []
                        for tc in to_copy:
                            # 数据移动1：目标是cache O
                            if tc[0][1] == 'CO':
                                dest_op = layer.memory_operand_links['O']
                            else:
                                # 不是CO的基本就是I或者O，就不用特殊处理了，residual因为只用了I1，所以特殊处理一下
                                dest_op = layer.memory_operand_links[tc[0][1]]
                                if dest_op == 'Y' and copied_I1:
                                    dest_op = 'I1'

                            source_op = 'O'
                            # 如果数据移动的源头是Cache I
                            if tc[0][0] == 'CI':
                                # 源数据来自O buffer，因为强制了cache数据必须在一片IO 共享的buffer里
                                source_op = layer.memory_operand_links[tc[0][1]]  # assume same operand as input (memorylevel is shared anyways)

                            # 获取源操作数mem lv
                            source_memlevel = self.accelerator.get_core(layer.core_allocation).memory_hierarchy.get_memorylevel_with_id(tc[1].get_id())

                            # 获取目标操作数mem lv
                            if tc[0][1] == 'CO':
                                # 如果是cache O，那么就从全部mem lv中寻找数据
                                dest_memlevel = self.accelerator.get_core(layer.core_allocation) \
                                    .memory_hierarchy.get_memorylevel_with_id(tc[2].get_id())
                            else:
                                # 否则，就从当前tile的mem中寻找数据
                                dest_memlevel = memhier.get_memorylevel_with_id(tc[2].get_id())

                            # 如果是stack in，那么源操作数WL中定义的O的存储位置（一般是I1）
                            if tc[0][0] == 'SI':
                                source_op = layer.memory_operand_links['O']

                            if tc[0][0] == 'R':
                                source_op = layer.memory_operand_links['X']

                            to_copy_actions.append(
                                DataCopyAction(tc[3],
                                               (source_op, source_memlevel.mem_level_of_operands[source_op]),
                                               (dest_op, dest_memlevel.mem_level_of_operands[dest_op]),
                                               self.accelerator.get_core(layer.core_allocation)))
                        dcl = DataCopyLayer(f'datamovement_b4_{layer}', to_copy_actions, self.accelerator, layer.core_allocation)  # will save to return this after the substage ran correctly

                        # done processing these, clear the array
                        to_copy.clear()



                        # create and call substage
                        # 已经准备好了所有的输入数据，并且确定了mem的级别，开始尝试评估这个tile的开销
                        try:    # 因为分配的空间不一定够？？为啥？尝试运行一下，如果不成功就加mem
                                # try except to catch edge cases where reserved space turns out not to be enough, in which case we throw stuff at the wall
                            if is_substack_input:
                                pass
                                # 这时什么也不用做，因为input node的作用是从DRAM搬数据，空间肯定是够的，而且数据移动的延时再data copy action处评估过了
                                # nothing to run here. Only a copy (fetch) of data needs to be done. This is registered above
                            else:
                                kwargs_2_ps = self.kwargs.copy()
                                kwargs_2_ps['accelerator'] = accelerator_mem_level_removed
                                kwargs_2_ps['layer'] = layer
                                sub_stage = self.list_of_callables[0](self.list_of_callables[1:], **kwargs_2_ps)   #= substage 入口
                                sub_stage_gen = sub_stage.run()
                                cme, extra_info = next(sub_stage_gen)
                                logger.debug('MAC utilization0: ' + str(cme.MAC_utilization0))
############################################################### substage 入口 ###############################################################################################################
                                _exhausted = object()
                                if next(sub_stage_gen, _exhausted) is not _exhausted:
                                    raise ValueError("Subcallable of df_pipeline yields more than one result, which df_pipeline does not know what to do with. Consider using a reduce.MinimalEnergyStage.")


                        # 关于每级mem是否安排为double buffer，参见cost_model.py 487~482



                        # MemHierarchyTooSmallException 位于memory allocator.py 143~144行，是尝试将loop安排在mem上，如果mem都用完了但只有没有分配的loop就会引入这个错误
                        except MemHierarchyTooSmallException as e:  # start throwing
                            # 先尝试加一级输出buffer
                            if extra_output_memlevels_because_it_did_not_work == extra_input_memlevels_because_it_did_not_work:  # equal state, increase output
                                extra_output_memlevels_because_it_did_not_work += 1
                            # 加output buffer不起作用，就加input buffer
                            elif extra_output_memlevels_because_it_did_not_work > extra_input_memlevels_because_it_did_not_work:  # increasing output did not work, try input
                                extra_input_memlevels_because_it_did_not_work += 1
                                extra_output_memlevels_because_it_did_not_work -= 1
                            # 还是不起作用就两个一起加
                            else:  # tried input => raise to both
                                extra_output_memlevels_because_it_did_not_work += 1  # now both are increased
                            logger.info(f"MemoryLevels were too optimistic => retrying for this layer with extra levels {extra_output_memlevels_because_it_did_not_work} for O and {extra_input_memlevels_because_it_did_not_work} for I")
                            # 因为mem不够，所以不能直接运行cost model，增加mem后重试
                            continue  # do again with extra memorylevel now


                        # 如果mem安排合适，能够放下loop，那么开始记录下cost model评估的开销
                        # 两部分，首先是数据移动阶段的开销
                        best_cme_per_layer_tile[f'datamovement_b4_{layer}'] = dcl, [f'datamovement_b4_{layer}']
                        # 如果不是InputNode，那么还需要记录下cost model评估出来的时间
                        if not is_substack_input:
                            best_cme_per_layer_tile[layer.id] = cme, [layer, extra_info]

                        # Register DataCopyActions for outputs
                        # To deal with the overlap, we first do caches for vertical reuse, as by doing this the overlap
                        # will have passed (or ended up) in the ml for horizontal reuse caching as well,
                        # as the ml for caching for vertical reuse is at least as high as the one for horizontal reuse

                        # 当前tile已经计算完成，那么就需要将这个tile的output 写到cache mem中去（overlap）
                        # 先列方向缓存，再行方向缓存

                        # 已经在vertical cache 中存储，不需要重复在horizonal中存储的数据量
                        subtract_vertical_from_horizontal = None # amount to not copy for horizontal, as its already copied for vertical cache
                        # 现在开始处理列方向缓存
                        if make_horizontal_cache_ml is not None and make_horizontal_cache_ml != memories_to_take_for_O[-1] \
                                and layer.id in horizontal_write_columns:
                            amount_bits_factors = {k: layer.loop_dim_size[k] for k in layer.operand_loop_dim['O']['r']}
                            amount_bits_factors[horizontal_write_columns[layer.id][0]] = horizontal_write_columns[layer.id][1]
                            amount_bits_factors['precision'] = layer.operand_precision['O_final']
                            if subtract_vertical_from_horizontal is not None:
                                amount_bits_factors[subtract_vertical_from_horizontal[0]] -= subtract_vertical_from_horizontal[1]

                            amount_bits = prod(amount_bits_factors.values())
                            if amount_bits>0 and not isinstance(layer, InputLayerNode) :
                                to_copy.append((('O', 'CO'), memories_to_take_for_O[-1], make_horizontal_cache_ml, amount_bits))
                                logger.debug("Added to copy output (H) -> cached_output: " + str(tuple(a if not isinstance(a, MemoryLevel) else a.memory_instance.name for a in to_copy[-1])) + " = " + '*'.join(str(f) for f in amount_bits_factors.values()))
                        # 处理完退出while 循环
                        break
                # 结束对单个tile的评估
                run_for_tilesize_cache[args] = best_cme_per_layer_tile
                return best_cme_per_layer_tile

            # 这里因为记录了前一层的output mem是哪个，所以不强制存储cache的mem是IO共享的
            # 上面完成了对一个tile进行评估的方法，但是每个tile要缓存多少overlap还有待模拟

            # NOTODO: basically in this whole code, make sure that memorylevels used to pass feature map tiles between \
            # layers are memories for both I and O, otherwise none of this makes any sense
            # NOPE => now code checks to whether input memorylevel is output memorylevel of predecessor anyways,
            # so this can just deal with that

            ####################################################################
            #= 决定每个tile要缓存多少cache
            # 评估一个tile overlap 存储在哪里的方法：
            # 1. 这里只考虑H方向cache就行
            # 2. tile的大小之类的要按照正向推导
            # 3. 如果未来需要专门的overlap buffer，应该从这里搞，把所有要cache的数据都放在overlap buffer
            ####################################################################
            determine_horizontal_caching_ml_for_tilesize_cache = {}
            def determine_caching_for_tilesize(tile_x:int,
                                               tile_y:int,
                                               first_x:bool,
                                               first_y:bool,
                                               last_x:bool,
                                               last_y:bool,
                                               horizontal_caching:bool,  # unused, oops
                                               ) \
                    -> Tuple[MemoryLevel,
                            #  MemoryLevel,
                             Dict[LayerNode, int],
                             Dict[LayerNode, int],
                            #  Dict[LayerNode, int],
                            #  Dict[LayerNode, int],
                             MemoryLevel]:
                # cache results for runtime optimization
                tilesize_to_determine_cachesize = (tile_x, tile_y, first_x, first_y, last_x, last_y, horizontal_caching)
                if tilesize_to_determine_cachesize in determine_horizontal_caching_ml_for_tilesize_cache:
                    return determine_horizontal_caching_ml_for_tilesize_cache[tilesize_to_determine_cachesize]


                workload_copy = pickle_deepcopy(usefull_workload)
                # workload_copy_with_inputlayer = pickle_deepcopy(workload_copy)
                #
                # for n in list(workload_copy.nodes()):
                #     if isinstance(n, InputLayerNode):
                #         workload_copy.remove_node(n)
                # 推导出每层每个tile需要读取和写出的overlap的数据量
                usefull_nodes, \
                to_cache_horizontally_out, \
                to_cache_horizontally_in = forwardpropagete_tilesize(workload_copy, tile_x, tile_y, first_x, first_y, last_x, last_y,
                                                                     not first_x,   # use horizontal caching
                                                                     True)
                # 这一次调用是根据实际的cache策略更新计算图中对每层tile size的描述
                workload_copy_for_largest_alive_size = pickle_deepcopy(usefull_workload)
                logger.debug('horizontal_caching: '+ self.horizontal_caching)
                _, \
                _, \
                _ = forwardpropagete_tilesize(
                    workload_copy_for_largest_alive_size,
                    tile_x, tile_y, first_x, first_y, last_x, last_y, #tilesize
                    not first_x and self.horizontal_caching,  # use horizontal caching
                    True)    # make horizontal caching

                # 计算需要的最大的用来存储所有特征的数据量
                largest_input_plus_output_size = get_largest_alive_size(workload_copy_for_largest_alive_size)

                # 输入特征应该cache的数据量
                to_cache_horizontally_bits_in = {}
                for n, I in to_cache_horizontally_in:
                    dim, size = to_cache_horizontally_in[(n,I)]
                    # r的话，是同一个索引，不会有overlap的，（比如residual的ox和oy）
                    if dim in n.operand_loop_dim[I]['r']:
                        assert size == 0 # should be the case for r loops
                        elems = 0
                        # elems = n.operand_size_elem[I] // n.operand_loop_dim[I]['r'][dim] * size
                    else:
                        # 不是r的话，代表有某种计算关系（pr），数据量// 循环维度 * overlap
                        # 除了h方向，每个方向都要size个
                        elems = n.operand_size_elem[I] // n.calc_tensor_dims(I, n.loop_dim_size)[dim] * size
                    # 共需要缓存 数量*精度 这么多的数据
                    to_cache_horizontally_bits_in[(n, I)] = elems * n.operand_precision[I]

                # 输出特征应该cache的数据量（horizontally方向）
                to_cache_horizontally_bits_out = {}
                for n in to_cache_horizontally_out:
                    dim, size = to_cache_horizontally_out[n]
                    elems = n.operand_size_elem['O'] // n.loop_dim_size[dim] * size
                    to_cache_horizontally_bits_out[n] = elems * n.operand_precision['O_final']

                to_cache_overlapped_bits_in = {}
                # 这个指的应该是H V 方向的缓存有多少数据是重叠的
                for n,I in to_cache_horizontally_in:
                    # 对每个输入节点
                    # v_dim, v_size = to_cache_vertically_in[(n,I)]
                    h_dim, h_size = to_cache_horizontally_in[(n,I)]
                    # 如果h 或v 维度直接在n的loop中，那肯定没有overlap （比如residual的ox和oy）
                    if h_dim in n.loop_dim_size:
                        assert to_cache_horizontally_bits_in[n,I] == 0
                        to_cache_overlapped_bits_in[(n, I)] = 0
                    else:
                        # 有多少块 * 每一块需要存储的数据量
                        h_tilesize = n.calc_tensor_dims(I, n.loop_dim_size)[h_dim]
                        # v_tilesize = n.calc_tensor_dims(I, n.loop_dim_size)[v_dim]
                        elems = n.operand_size_elem[I] // h_tilesize * h_size
                        to_cache_overlapped_bits_in[(n, I)] = elems * n.operand_precision[I]

                # if first tile in a row, we don't have all horizontal caches at once (except at the end)
                # So we figger out at every point in the network what is the number of features alive + all caches
                # created up until that point

                # 对一行中的第一个tile，没有行方向缓存
                # 所以动态层新下当前tile计算是mem中需要的特征和cache数据的总量
                peak_f_mem_size = get_largest_alive_size(workload_copy_for_largest_alive_size)

                # I是映射到I1或I2且没有被标记为constant的数据
                i_mem_op = next(n.memory_operand_links[I] for n in usefull_nodes for I in n.memory_operand_links if I not in n.constant_operands and n.memory_operand_links[I]!= 'O')
                # O是映射到O的数据
                o_mem_op = next(n.memory_operand_links['O'] for n in usefull_nodes if 'O' in n.memory_operand_links)
                # get lowest memory that fits largest fm, to reserve space that can not be used for weights
                # and is also not unrolled

                # 为IO预留的mem，能够放下peak mem的需求，并且不能是unroll的
                # 这里必须是IO共享的一片mem，这个干啥的？？？
                memories_to_reserve_for_IO = []
                for i, ml in enumerate(mh.get_memory_levels(o_mem_op)):
                    memories_to_reserve_for_IO.append(ml)
                    if i_mem_op in ml.operands and ml.memory_instance.size >= largest_input_plus_output_size and ml.unroll_count == 1:
                        break
                io_mem_level = memories_to_reserve_for_IO[-1]

                # 根据cache数据更新peak mem size
                if horizontal_caching:
                    if first_x:
                        # x方向第一块的话，只需要cache他的输出
                        peak_f_mem_size = get_largest_alive_size(workload_copy_for_largest_alive_size, to_cache_horizontally_bits_out)
                    else:
                        # Otherwise all caches are present
                        # 否则要加上他的所有输入（为啥不用加上输出？？？是所有层的输入？后一层的输入就是前一层的输出的意思？）
                        peak_f_mem_size = largest_input_plus_output_size + sum(to_cache_horizontally_bits_in.values())
                    peak_f_mem_size_h = peak_f_mem_size
                    horizontal_caching_ml : MemoryLevel
                    memory_hierarchy = self.accelerator.get_core(next(n for n in usefull_workload.topological_sort() if hasattr(n, 'core_allocation')).core_allocation).memory_hierarchy

                    # Find lowest memory level that
                    #  - fits horizontal at the same time as largest amount of alive features (see if statement above=> peak_mem size)
                    #  - is shared between inputs and outputs
                    #  - is not unrolled

                    # 寻找能cache H方向数据的mem
                    # 1. 首先能存下horizontal和所有alive feature
                    # 2. 被输入和输出共享
                    # 3. 没被unroll
                    for i, ml in enumerate(memory_hierarchy.get_memory_levels('O')):
                        if ml.memory_instance.size >= peak_f_mem_size and i_mem_op in ml.operands and ml.unroll_count == 1:
                            horizontal_caching_ml = ml
                            logger.info(f"Caching for horizontal reuse in memorylevel {ml} for tile {tile_x}x{tile_y}" +
                                        (" (firstx)" if first_x else "") + (" (firsty)" if first_y else ""))
                            break

                    # 如果同时还有H方向缓存
                    # if vertical_caching:
                    #     # Find lowest memory level that
                    #     #  - fits horizontal at the same time as largest amount of alive features (see if statement above=> peak_mem size)
                    #     #    and now also caches for vertical reuse
                    #     #  - is shared between inputs and outputs
                    #     #  - is not unrolled

                    #     # 1. 能存下H V以及alive features
                    #     # 2. IO共享
                    #     # 3. 不是被unroll的
                else:
                    horizontal_caching_ml = None
                    # vertical_caching_ml = None

                # weights have lowest priority, so lowest memorylevel that fits
                # - all weights
                # - if shared with I/O also all features and all caches, if included for

                # 权重具有最低的优先级，开始安排权重
                # 1. 能存下所有的权重
                # 2. 如果被IO共享，还要能存下所有的IO
                weights_total = sum(sum(layer.operand_size_bit[W] for W in layer.constant_operands) for layer in usefull_nodes)
                logger.debug(f"Weight size: {weights_total}")
                try:
                    w_mem_op = next(n.memory_operand_links['W'] for n in usefull_nodes if 'W' in n.memory_operand_links)
                    # lowest memory that also fits the weights
                    memories_to_take_for_W = []
                    # 依次尝试增加w mem lv
                    for i, ml in enumerate(mh.get_memory_levels(w_mem_op)):
                        memories_to_take_for_W.append(ml)
                        size_to_fit = weights_total
                        if ml in memories_to_reserve_for_IO:
                            size_to_fit = weights_total + largest_input_plus_output_size
                        if ml == horizontal_caching_ml:
                            size_to_fit = weights_total + peak_f_mem_size_h
                        if ml.memory_instance.size >= size_to_fit:
                            break
                    weight_ml = memories_to_take_for_W[-1]
                    logger.info(f"Weights go to {weight_ml.memory_instance.name}")
                except StopIteration:
                    # no weights to be found here
                    w_mem_op = None
                    weight_ml = None

                # how many new columns to put in cache for this cache
                # This is just to_cache_horizontally, except for very small tilesizes where part of this is already
                # in cache from previous tile (So some inputs serve more than two tiles)
                # (same for rows) => need not to be written every time again

                # 要想cache中新增多少列数据
                # 有些输入可能不止被一个tile复用，不需要重复写入
                if first_x:
                    # 没行的第一个块肯定是没问题的，x方向都要缓存
                    columns_to_write = to_cache_horizontally_out
                else:
                    # 如果不是第一列块的话，0:dim   1:to cache ,取to cache和loop dim中的较小值
                    columns_to_write = {l: (to_cache_horizontally_out[l][0],
                                            min(
                                                to_cache_horizontally_out[l][1],
                                                l.loop_dim_size[to_cache_horizontally_out[l][0]]
                                            )) for l in to_cache_horizontally_out}

                columns_to_read = defaultdict(return_0) if first_x else to_cache_horizontally_in
                rows_to_read = defaultdict(return_0)
                #dataformat change, no new intelligence here
                columns_to_write = {l.id: columns_to_write[l] for l in columns_to_write}
                columns_to_read = {(l[0].id, l[1]): columns_to_read[l] for l in columns_to_read}

                # caching of this functions output for runtime optimization
                determine_horizontal_caching_ml_for_tilesize_cache[tilesize_to_determine_cachesize] = \
                    (horizontal_caching_ml, columns_to_write, columns_to_read, weight_ml)

                return determine_horizontal_caching_ml_for_tilesize_cache[tilesize_to_determine_cachesize]

            ################################################################################
            # 初次迭代，确定所有tile间应该保持不变的数据
            # 比如overlap存储的级别（所有tile应该是相同的，所以强制拉到最高）， 或许一个专门的overlap buffer？？
            # 一个stack内部weight 的最高级应该是不变的（所有tile的最高级）
            ################################################################################
            leftover_tilesize_x = total_OX % self.tilesize_x
            if leftover_tilesize_x == 0:
                leftover_tilesize_x = self.tilesize_x

            ############################################
            # A first iteration through all tiles to
            # deal with all stuff that must be consistent
            # across tiles, such as
            # - vertical caching ml across rows  (level = highest overall)
            # - horizontal caching ml across neighbouring columns (level = max of 2 horizontal neighbours)
            # - weight ml (highest overall)

            # 通过所有tile的第一次迭代来处理所有必须在瓦片之间保持一致的东西，例如
            # -跨行垂直缓存ml（级别=总体最高）
            # -跨相邻列的水平缓存ml（级别=最大2个水平邻居）
            # -重量ml（整体最高）
            ############################################

            mh : MemoryHierarchy = self.accelerator.get_core(next(n for n in nx.topological_sort(self.workload) if hasattr(n, 'core_allocation')).core_allocation ).memory_hierarchy
            mh_sorted = list(nx.topological_sort(mh))


            highest_w_ml = None
            highest_vertical_cache_ml = None
            horizontal_caching_info = {}  # key = x0,y0; values = tuples of make_ml, write_columns, read_columns
            # vertical_caching_info = {}  # similar
            y0 = 0
            workload_copy = pickle_deepcopy(usefull_workload)
            _, \
            _, \
            _, = forwardpropagete_tilesize(
                workload_copy, self.tilesize_x, self.tilesize_y, False, False, False, False,    # tile size
                self.horizontal_caching,    # use horizontal caching
                True)
            y_stride = get_y_stride(workload_copy)
            logger.debug("Stride " + str(y_stride))

            logger.debug("determine_caching_for_tilesize.")
            logger.debug("total_OY" + str(total_OY))
            logger.debug("tilesize y " + str(self.tilesize_y))

            flag_x = 0
            flag_y = 0
            while not flag_y:
                logger.debug("y0" + str(y0))
                this_tile_y = min(self.tilesize_y, total_OY - y0)
                assert y0 + this_tile_y <= total_OY
                x0 = 0
                flag_x = 0

                while not flag_x:
                    logger.debug("x0 " + str(x0))
                    this_tile_x = min(self.tilesize_x, total_OX - x0)
                    assert x0 + this_tile_x <= total_OX

                    horizontal_caching_ml, \
                    horizontal_cache_write_columns, \
                    horizontal_cache_read_columns, \
                    w_ml = determine_caching_for_tilesize(
                                                        this_tile_x, this_tile_y, x0 == 0, y0 == 0,
                                                        x0 + self.tilesize_x >= total_OX,
                                                        y0 + self.tilesize_y >= total_OY,
                                                        self.horizontal_caching)
                    if self.horizontal_caching:
                        if x0 + self.tilesize_x >= total_OX:
                            horizontal_caching_info[(x0, y0)] = [None, defaultdict(return_emtpystr_0_list), horizontal_cache_read_columns]
                        elif x0 == 0:
                            horizontal_caching_info[(x0, y0)] = [horizontal_caching_ml, \
                                                                 horizontal_cache_write_columns, \
                                                                 horizontal_cache_read_columns]
                        else:
                            horizontal_caching_info[(x0, y0)] = [horizontal_caching_ml, \
                                                                 horizontal_cache_write_columns, \
                                                                 horizontal_cache_read_columns]
                        if x0 != 0:
                            # If caching ml of this tile is higher than for previous tile, make sure previous tile
                            # makes to this memory level
                            previous = horizontal_caching_info[(previous_x0, y0)][0]
                            if previous != horizontal_caching_ml:  # (line not required algorithmically, but makes it faster)
                                previous = previous.get_id()
                                this = horizontal_caching_ml.get_id()
                                for ml in mh_sorted:
                                    if ml.get_id() == previous:  # previous hit first so new one is higher
                                        horizontal_caching_info[(previous_x0, y0)][0] = horizontal_caching_ml
                                        break
                    else:
                        horizontal_caching_info[(x0, y0)] = (None, defaultdict(return_emtpystr_0_list), defaultdict(return_0))

                    if highest_w_ml is None:
                        highest_w_ml = w_ml
                    else:
                        if highest_w_ml != w_ml:  # (line not required algorithmically, but makes it faster)
                            h = mh.get_memorylevel_with_id(highest_w_ml.get_id())
                            new = mh.get_memorylevel_with_id(w_ml.get_id())
                            for ml in mh_sorted:
                                if ml == h:  # h hit first, so new one is higher
                                    highest_w_ml = new
                                    break
                                if ml == new:
                                    highest_w_ml = h
                                    break
                    previous_x0 = x0

                    if flag_x:
                        break
                    if x0 + self.tilesize_x >= total_OX:
                        flag_x = 1
                    x0 += this_tile_x

                if flag_y:
                    break
                if y0 + self.tilesize_y >= total_OY:
                    flag_y = 1
                y0 += this_tile_y



            # # InputLayerNodes where only there for get_largest_alive_size
            # # This is no longer needed, and rest of used code is not equipped to deal with these InputLayerNodes
            # for n in list(usefull_workload.nodes()):
            #     if isinstance(n, InputLayerNode):
            #         usefull_workload.remove_node(n)

            ##################################
            # Actually do all the tiles
            #= 开始实际评估这些tile
            ##################################
            weights_from_top = True
            y0 = 0

            previous_y0 = None
            logger.debug("Run for tile size.")
            flag_x = 0
            flag_y = 0


            while not flag_y:
                logger.debug("run for tile size y" + str(y0))
                this_tile_y = min(self.tilesize_y, total_OY - y0)
                assert y0 + this_tile_y <= total_OY
                previous_x0 = None
                x0 = 0
                flag_x = 0
                while not flag_x:
                    logger.debug("run for tile x" + str(y0))
                    this_tile_x = min(self.tilesize_x, total_OX - x0)
                    assert x0 + this_tile_x <= total_OX

                    make_horizontal_cache_ml, horizontal_cache_write_columns, horizontal_cache_read_columns = \
                        horizontal_caching_info[(x0, y0)]

                    if x0:
                        use_horizontal_cache_ml = horizontal_caching_info[(previous_x0, y0)][0]
                    else:
                        use_horizontal_cache_ml = None

                    assert(x0 + self.tilesize_x < total_OX or make_horizontal_cache_ml is None)

                    logger.debug("Start run for tilesize.")
                    energy_of_this_tile = run_for_tilesize(this_tile_x, this_tile_y, weights_from_top,
                                                           x0 == 0, y0 == 0,
                                                           x0 + self.tilesize_x >= total_OX,
                                                           y0 + self.tilesize_y >= total_OY,
                                                           make_horizontal_cache_ml,
                                                           use_horizontal_cache_ml,
                                                           horizontal_cache_write_columns,
                                                           horizontal_cache_read_columns,
                                                           highest_w_ml,
                                                           x0, y0)
                    # see if result was already seen
                    # If so, just increase its multiplier (runtime optimization)
                    for k, v in energy_of_this_tile.items():
                        try:
                            # v is in there, adjust multiplier. Otherwise exception is raised
                            index = [i[0] for i in cost_model_evaluations_per_layer[k]].index(v)
                            #Note: CostModelEvaluation has no __eq__ implementation and therefore resorts to comparing
                            #based on id, which is already due to run_for_tilesize actually the exact same instance
                            #due to that it caches its outputs
                            cost_model_evaluations_per_layer[k][index][1] += 1
                        except ValueError:
                            # v was not in there, add it with multiplier 1
                            cost_model_evaluations_per_layer[k].append([v, 1])

                    # after first tile, weights no longer need to come from top memory level
                    weights_from_top = False

                    # next horizontal cache ml to read from (use) (in the next tile), is the one we wrote to (make) now
                    if self.horizontal_caching:
                        use_horizontal_cache_ml = make_horizontal_cache_ml
                    previous_x0 = x0

                    if flag_x:
                        break
                    if x0 + self.tilesize_x >= total_OX:
                        flag_x = 1
                    x0 += this_tile_x

                previous_y0=y0

                if flag_y:
                    break
                if y0 + self.tilesize_y >= total_OY:
                    flag_y = 1
                y0 += y_stride
            # assert y0 == total_OY
            # assert x0 == total_OX


        # Done, accumulate and yield results
        for k in cost_model_evaluations_per_layer:
            total = None
            for cme, mul in cost_model_evaluations_per_layer[k]:
                cme, extra_info = cme
                if total is None:
                    total = cme * mul
                else:
                    total += cme * mul
            total.accelerator = self.accelerator
            yield total, cost_model_evaluations_per_layer[k]

        # Print some stuff to logger
        longest_layer_name = max(len(str(l)) for l in cost_model_evaluations_per_layer)
        for layer, cm_list in cost_model_evaluations_per_layer.items():
            logger.info(("Layer {layer:>"+str(longest_layer_name)+"s} best energy found = {best_energy:20,d}  with latency {latency:30,d}")
                        .format(layer=str(layer),
                                best_energy=int(sum(cm[0].energy_total*mul for cm, mul in cm_list)),
                                latency=int(sum(cm[0].latency_total2 * mul for cm, mul in cm_list))))

